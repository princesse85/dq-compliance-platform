# Project Structure

## Overview

The Enterprise Data Quality Platform follows a modular, production-ready architecture with clear separation of concerns and enterprise-grade organization.

## Directory Structure

```
enterprise-data-quality-platform/
â”œâ”€â”€ ğŸ“ docs/                          # Documentation
â”‚   â”œâ”€â”€ architecture.md               # Architecture overview
â”‚   â””â”€â”€ project-structure.md          # This file
â”œâ”€â”€ ğŸ“ src/                           # Source code
â”‚   â”œâ”€â”€ ğŸ“ data_quality/              # Data quality framework
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_validation_suite.py  # Great Expectations validation
â”‚   â”‚   â”œâ”€â”€ generate_synthetic_data.py # Test data generation
â”‚   â”‚   â”œâ”€â”€ quality_assessment.py     # Quality scoring and monitoring
â”‚   â”‚   â””â”€â”€ utils.py                  # Validation utilities
â”‚   â”œâ”€â”€ ğŸ“ etl_pipelines/             # ETL processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ contracts_etl_job.py      # Glue ETL job for contracts
â”‚   â”œâ”€â”€ ğŸ“ machine_learning/          # ML capabilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ baseline_tf_idf.py        # Baseline ML model
â”‚   â”‚   â”œâ”€â”€ eval_report.py            # Model evaluation
â”‚   â”‚   â”œâ”€â”€ mlflow_utils.py           # MLflow integration
â”‚   â”‚   â”œâ”€â”€ transformer_train.py      # Transformer model training
â”‚   â”‚   â””â”€â”€ ğŸ“ explain/               # Model explainability
â”‚   â”‚       â”œâ”€â”€ global_words.py       # Global feature importance
â”‚   â”‚       â””â”€â”€ lime_explain.py       # LIME explanations
â”‚   â””â”€â”€ ğŸ“ data/                      # Data preparation
â”‚       â””â”€â”€ prepare_text_corpus.py    # Text corpus preparation
â”œâ”€â”€ ğŸ“ stacks/                        # AWS CDK infrastructure
â”‚   â”œâ”€â”€ foundation_stack.py           # Core infrastructure
â”‚   â”œâ”€â”€ data_quality_stack.py         # Data quality components
â”‚   â”œâ”€â”€ billing_alarm_stack.py        # Cost monitoring
â”‚   â””â”€â”€ ml_inference_stack.py         # ML inference API
â”œâ”€â”€ ğŸ“ tests/                         # Test suite
â”œâ”€â”€ ğŸ“ lambda_app/                    # Lambda application
â”‚   â”œâ”€â”€ app/                          # Lambda function code
â”‚   â”œâ”€â”€ Dockerfile                    # Container definition
â”‚   â”œâ”€â”€ requirements.txt              # Lambda dependencies
â”‚   â”œâ”€â”€ build_and_deploy.sh           # Deployment script
â”‚   â””â”€â”€ test_api.py                   # API testing
â”œâ”€â”€ ğŸ“ assets/                        # Static assets
â”‚   â”œâ”€â”€ sample_contract_register.csv  # Sample data
â”‚   â””â”€â”€ image_showcase.png            # Documentation images
â”œâ”€â”€ ğŸ“ data/                          # Data directories
â”‚   â”œâ”€â”€ raw/                          # Raw data storage
â”‚   â”œâ”€â”€ processed/                    # Processed data storage
â”‚   â””â”€â”€ text_corpus/                  # ML training data
â”œâ”€â”€ ğŸ“ analytics/                     # Analytics outputs
â”‚   â””â”€â”€ models/                       # Trained models
â”œâ”€â”€ ğŸ“ mlruns/                        # MLflow experiment tracking
â”œâ”€â”€ ğŸ“ cdk.out/                       # CDK build outputs
â”œâ”€â”€ ğŸ“„ README.md                      # Main documentation
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md                # Contribution guidelines
â”œâ”€â”€ ğŸ“„ LICENSE                        # MIT License
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ env.example                    # Environment variables template
â”œâ”€â”€ ğŸ“„ cdk.json                       # CDK configuration
â”œâ”€â”€ ğŸ“„ app.py                         # CDK application entry point
â””â”€â”€ ğŸ“„ .gitignore                     # Git ignore rules
```

## Key Components

### Infrastructure (CDK Stacks)

#### Foundation Stack (`stacks/foundation_stack.py`)

- **S3 Buckets**: Raw, processed, analytics data lakes
- **IAM Roles**: Admin, Data Engineer, Reviewer groups
- **CloudTrail**: Audit logging and compliance
- **Glue Database**: Data catalog foundation

#### Data Quality Stack (`stacks/data_quality_stack.py`)

- **Glue Crawlers**: Automatic schema discovery
- **ETL Jobs**: Data transformation pipelines
- **IAM Roles**: Glue service permissions
- **Quality Framework**: Great Expectations integration

#### Billing Alarm Stack (`stacks/billing_alarm_stack.py`)

- **Budget Alerts**: Cost monitoring and notifications
- **SNS Topics**: Alert distribution
- **CloudWatch**: Billing metrics and alarms

#### ML Inference Stack (`stacks/ml_inference_stack.py`)

- **Lambda Functions**: Model serving
- **API Gateway**: RESTful API endpoints
- **ECR Repository**: Container image storage
- **SSM Parameters**: Configuration management

### Data Quality Framework (`src/data_quality/`)

#### Core Components

- **Validation Suite**: Great Expectations validation rules
- **Quality Assessment**: Automated quality scoring
- **Synthetic Data**: Test data generation
- **Utilities**: Validation helper functions

#### Features

- Automated data validation
- Quality score calculation
- Compliance monitoring
- Audit trail generation

### ETL Pipelines (`src/etl_pipelines/`)

#### Processing Jobs

- **Contracts ETL**: Contract data transformation
- **Data Cleaning**: Standardization and validation
- **Schema Evolution**: Automatic schema updates
- **Quality Gates**: Validation checkpoints

### Machine Learning (`src/machine_learning/`)

#### Model Development

- **Baseline Models**: TF-IDF based classifiers
- **Transformer Models**: Advanced NLP models
- **Model Evaluation**: Performance assessment
- **Explainability**: Model interpretation tools

#### ML Operations

- **MLflow Integration**: Experiment tracking
- **Model Registry**: Version control
- **A/B Testing**: Model comparison
- **Monitoring**: Performance tracking

### Lambda Application (`lambda_app/`)

#### API Services

- **Model Serving**: Real-time inference
- **Explanation API**: Model interpretability
- **Health Checks**: Service monitoring
- **Error Handling**: Robust error management

## Configuration Management

### Environment Variables (`env.example`)

- **AWS Configuration**: Region, profile settings
- **Project Settings**: Prefix, environment names
- **Data Lake**: Bucket configurations
- **Quality Settings**: Thresholds and parameters
- **ML Configuration**: Model and training settings
- **Security**: Encryption and access controls

### CDK Configuration (`cdk.json`)

- **Project Context**: Environment-specific settings
- **Resource Naming**: Consistent naming conventions
- **Budget Controls**: Cost management settings
- **Environment Support**: Multi-environment deployment

## Development Workflow

### Local Development

1. **Environment Setup**: Virtual environment and dependencies
2. **Configuration**: Environment variables and AWS setup
3. **Testing**: Unit, integration, and e2e tests
4. **Code Quality**: Linting, formatting, and type checking

### Deployment Pipeline

1. **Infrastructure**: CDK deployment to target environment
2. **Data Pipeline**: ETL job execution and validation
3. **Quality Assessment**: Automated quality checks
4. **Monitoring**: Performance and cost monitoring

### Quality Assurance

- **Code Review**: Pull request process
- **Testing**: Automated test suites
- **Documentation**: Comprehensive documentation
- **Security**: Security scanning and compliance

## Best Practices

### Code Organization

- **Modular Design**: Clear separation of concerns
- **Type Hints**: Comprehensive type annotations
- **Documentation**: Docstrings and comments
- **Error Handling**: Robust error management

### Security

- **Least Privilege**: Minimal required permissions
- **Encryption**: Data encryption at rest and in transit
- **Audit Logging**: Comprehensive audit trails
- **Access Control**: Role-based access management

### Performance

- **Optimization**: Efficient data processing
- **Monitoring**: Real-time performance tracking
- **Scaling**: Auto-scaling capabilities
- **Cost Management**: Resource optimization

### Compliance

- **Data Governance**: Data lineage and tracking
- **Quality Assurance**: Automated quality validation
- **Audit Trails**: Complete audit logging
- **Regulatory Compliance**: GDPR, SOX, HIPAA support

