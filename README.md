<!-- README.md -->

# End-to-End Data Quality & Compliance Automation Platform

A cloud-native platform that ingests heterogeneous documents, raises data-quality scores, and detects contractual compliance risks with NLP + ML.  
The repository contains infrastructure-as-code (Terraform), PySpark pipelines, ML workflows (MLflow / SageMaker), and CI/CD automation.

---

## ğŸ“ High-Level Architecture

![Data Architecture Flow](assets/image_showcase.png)

---

## ğŸ¯ Key Objectives

- **Multi-format ingestion** at scale (CSV, XLSX, PDF, DOCX).
- **Data-quality uplift** â‰¥ 85 % within the first month.
- **Clause-level compliance-risk detection** using Gradient-Boost & Isolation Forest.
- **Cost-aware hybrid cloud**: free-tier RDS, spot EMR, student AWS credits.
- **Research contribution**: empirical comparison of TF-IDF vs. Transformer embeddings for legal-risk scoring.

---

## ğŸ—‚ Repository Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ dev.Dockerfile
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ terraform/
â”‚       â”œâ”€â”€ s3_landing_zone.tf
â”‚       â””â”€â”€ variables.tf
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ sample_address_book.csv
â””â”€â”€ src/
    â”œâ”€â”€ ingestion/
    â”‚   â””â”€â”€ ingest_csv.py
    â”œâ”€â”€ processing/
    â”œâ”€â”€ dq/
    â”œâ”€â”€ nlp/
    â””â”€â”€ ml/
```

---

## ğŸš€ Quick Start

```bash
# Clone and enter the project
git clone https://github.com/<org>/dq-compliance-platform.git
cd dq-compliance-platform

# Build the local dev container
docker build -f docker/dev.Dockerfile -t dq-dev .

# Run container with AWS credentials
docker run --rm -it \
  -v ${PWD}:/workspace \
  -v ~/.aws:/root/.aws \
  -e DQ_BUCKET=<landing-zone-bucket> \
  dq-dev bash

# Upload sample data to S3
./infrastructure/scripts/upload_sample_data.sh
```

> **Prerequisites**
>
> - AWS CLI configured with an account that has S3 + Glue + Textract permissions
> - Terraform â‰¥ 1.6 for infrastructure deployment

---

## ğŸ›  Technology Stack

| Layer                    | Tooling (primary)                               |
| ------------------------ | ----------------------------------------------- |
| **Code / Orchestration** | Python 3.10 Â· PySpark 3.5 Â· Docker Â· Terraform  |
| **Data-Quality**         | Great Expectations                              |
| **NLP**                  | Spark NLP                                       |
| **Machine Learning**     | MLflow Â· SageMaker Processing                   |
| **Storage**              | S3 (raw + curated) Â· PostgreSQL (RDS free tier) |
| **BI & Alerting**        | Amazon QuickSight Â· Amazon SNS / Slack          |
| **CI/CD & Ops**          | GitHub Actions Â· CloudWatch Â· Cost Explorer     |

---

## ğŸ§ª Test & Validation

- **Unit tests**: PyTest, target 60â€“70 % coverage.
- **Data-quality assertions**: Great Expectations checkpoints in CI.
- **Model validation**: K-fold CV, SHAP explainability.
- **End-to-End UAT**: ingestion â†’ dashboard refresh â‰¤ 30 min.

---

## ğŸ—º Roadmap (excerpt)

| Phase                      | Timeline | Status         |
| -------------------------- | -------- | -------------- |
| 0 â€“ Design docs            | Week 1   | âœ… Done        |
| 1 â€“ Landing-zone S3 + Glue | Wks 2-3  | ğŸ”„ In progress |
| 2 â€“ Textract & Spark NLP   | Wks 4-5  | â³ Planned     |
| 3 â€“ Data-Quality Framework | Wks 6-7  | â³ Planned     |
| 4 â€“ ML Model Dev           | Wks 8-10 | â³ Planned     |

Full details in `docs/implementation_guide.md`.

---

## ğŸ· Cost-Control Guidelines

1. **Local-first dev**: run PySpark in Docker; push to Glue only for integration tests.
2. **Spot & Stop**: EMR clusters on spot instances, `--auto-terminate` after job finish.
3. **Free-tier analytics**: RDS micro, QuickSight Standard (< Â£15/mo).
4. **Continuous tagging**: every Terraform resource carries `Project = <ID>` for Cost Explorer.

---

## ğŸ¤ Contributing

Pull requests are welcome. Please fork the repo and create a feature branch prefixed with `feat/` or `fix/`.
All contributions must pass **ruff** linting and the PyTest suite in the GitHub Actions pipeline.

---

## ğŸ“œ Licence

This project is released under the MIT License. See `LICENSE` for details.
